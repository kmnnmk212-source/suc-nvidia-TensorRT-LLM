

الحمد لله
اشتغل

python 3.12
cudatookit 12.8
drriv 580
rtx5060ti16gb








https://nvidia.github.io/TensorRT-LLM/installation/linux.html#installing-on-linux

https://github.com/NVIDIA/TensorRT-LLM
























(venv) m@m-HP-Z440-Workstation:~/Desktop/1$ pip list
Package                  Version
------------------------ ------------
accelerate               1.11.0
aenum                    3.1.16
aiohappyeyeballs         2.6.1
aiohttp                  3.13.2
aiosignal                1.4.0
annotated-types          0.7.0
antlr4-python3-runtime   4.9.3
anyio                    4.11.0
attrs                    25.4.0
backoff                  2.2.1
blake3                   1.0.8
blobfile                 3.1.0
build                    1.3.0
certifi                  2025.10.5
cffi                     2.0.0
charset-normalizer       3.4.4
click                    8.3.0
click-option-group       0.5.9
colored                  2.3.1
contourpy                1.3.3
cuda-bindings            12.9.4
cuda-pathfinder          1.3.2
cuda-python              12.9.4
cycler                   0.12.1
datasets                 3.1.0
diffusers                0.35.2
dill                     0.3.8
distro                   1.9.0
einops                   0.8.1
etcd3                    0.12.0
evaluate                 0.4.6
fastapi                  0.115.4
filelock                 3.19.1
flashinfer-python        0.2.5
fonttools                4.60.1
frozenlist               1.8.0
fsspec                   2024.9.0
grpcio                   1.76.0
h11                      0.16.0
h5py                     3.12.1
hf-xet                   1.2.0
httpcore                 1.0.9
httpx                    0.28.1
huggingface-hub          0.36.0
idna                     3.11
importlib_metadata       8.7.0
Jinja2                   3.1.6
jiter                    0.11.1
kiwisolver               1.4.9
lark                     1.3.1
llguidance               0.7.29
lxml                     6.0.2
markdown-it-py           4.0.0
MarkupSafe               2.1.5
matplotlib               3.10.7
mdurl                    0.1.2
meson                    1.9.1
ml_dtypes                0.5.3
mpi4py                   4.1.1
mpmath                   1.3.0
multidict                6.7.0
multiprocess             0.70.16
networkx                 3.5
ninja                    1.13.0
numpy                    1.26.4
nvidia-cublas-cu12       12.8.3.14
nvidia-cuda-cupti-cu12   12.8.57
nvidia-cuda-nvrtc-cu12   12.8.61
nvidia-cuda-runtime-cu12 12.8.57
nvidia-cudnn-cu12        9.7.1.26
nvidia-cufft-cu12        11.3.3.41
nvidia-cufile-cu12       1.13.0.11
nvidia-curand-cu12       10.3.9.55
nvidia-cusolver-cu12     11.7.2.55
nvidia-cusparse-cu12     12.5.7.53
nvidia-cusparselt-cu12   0.6.3
nvidia-ml-py             12.575.51
nvidia-modelopt          0.33.1
nvidia-modelopt-core     0.33.1
nvidia-nccl-cu12         2.26.2
nvidia-nvjitlink-cu12    12.8.61
nvidia-nvtx-cu12         12.8.55
nvtx                     0.2.13
omegaconf                2.3.0
onnx                     1.19.1
onnx_graphsurgeon        0.5.8
openai                   2.6.1
opencv-python-headless   4.11.0.86
optimum                  2.0.0
ordered-set              4.1.0
packaging                25.0
pandas                   2.3.3
peft                     0.17.1
pillow                   10.3.0
pip                      25.3
polygraphy               0.49.26
propcache                0.4.1
protobuf                 6.33.0
psutil                   7.1.2
PuLP                     3.3.0
pyarrow                  22.0.0
pycparser                2.23
pycryptodomex            3.23.0
pydantic                 2.12.3
pydantic_core            2.41.4
pydantic-settings        2.11.0
Pygments                 2.19.2
pynvml                   12.0.0
pyparsing                3.2.5
pyproject_hooks          1.2.0
python-dateutil          2.9.0.post0
python-dotenv            1.2.1
pytz                     2025.2
PyYAML                   6.0.3
pyzmq                    27.1.0
regex                    2025.10.23
requests                 2.32.5
rich                     14.2.0
safetensors              0.6.2
scipy                    1.16.3
sentencepiece            0.2.1
setuptools               79.0.1
six                      1.17.0
sniffio                  1.3.1
soundfile                0.13.1
starlette                0.41.3
StrEnum                  0.4.15
sympy                    1.14.0
tenacity                 9.1.2
tensorrt                 10.11.0.33
tensorrt_cu12            10.11.0.33
tensorrt_cu12_bindings   10.11.0.33
tensorrt_cu12_libs       10.11.0.33
tensorrt_llm             1.0.0
tiktoken                 0.12.0
tokenizers               0.21.4
torch                    2.7.1+cu128
torchaudio               2.7.1+cu128
torchprofile             0.0.4
torchvision              0.22.1+cu128
tqdm                     4.67.1
transformers             4.53.1
triton                   3.3.1
typing_extensions        4.15.0
typing-inspection        0.4.2
tzdata                   2025.2
urllib3                  2.5.0
uvicorn                  0.38.0
wheel                    0.45.1
xgrammar                 0.1.21
xxhash                   3.6.0
yarl                     1.22.0
zipp                     3.23.0
(venv) m@m-HP-Z440-Workstation:~/Desktop/1$ 





history

  193  sudo apt update
  194  sudo apt install python3.12-venv python3.12-dev
  195  python3.12 -m venv venv
  196  source venv/bin/activate
  197  pip3 install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
  198  sudo apt-get -y install libopenmpi-dev
  199  sudo apt-get -y install libzmq3-dev
  200  pip3 install --upgrade pip setuptools && pip3 install tensorrt_llm
  201  source venv/bin/activate
  202  python
  203  pip3 install tensorrt_llm
  204  python 1.py
  205  pip list
  206  history
(venv) m@m-HP-Z440-Workstation:~/Desktop/1$ 


































m@m-HP-Z440-Workstation:~/Desktop/1$ source venv/bin/activate
(venv) m@m-HP-Z440-Workstation:~/Desktop/1$ python
Python 3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> exit()
(venv) m@m-HP-Z440-Workstation:~/Desktop/1$ pip3 install tensorrt_llm
Collecting tensorrt_llm
  Using cached tensorrt_llm-1.0.0.tar.gz (1.6 kB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Collecting accelerate>=0.25.0 (from tensorrt_llm)
  Using cached accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)
Collecting build (from tensorrt_llm)
  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)
Collecting colored (from tensorrt_llm)
  Using cached colored-2.3.1-py3-none-any.whl.metadata (3.6 kB)
Collecting cuda-python<13,>=12 (from tensorrt_llm)
  Using cached cuda_python-12.9.4-py3-none-any.whl.metadata (4.7 kB)
Collecting diffusers>=0.27.0 (from tensorrt_llm)
  Using cached diffusers-0.35.2-py3-none-any.whl.metadata (20 kB)
Collecting lark (from tensorrt_llm)
  Using cached lark-1.3.1-py3-none-any.whl.metadata (1.8 kB)
Collecting mpi4py (from tensorrt_llm)
  Using cached mpi4py-4.1.1-cp312-cp312-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (16 kB)
Collecting numpy<2 (from tensorrt_llm)
  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
Collecting onnx>=1.18.0 (from tensorrt_llm)
  Using cached onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)
Collecting onnx_graphsurgeon>=0.5.2 (from tensorrt_llm)
  Using cached onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl.metadata (8.2 kB)
Collecting openai (from tensorrt_llm)
  Using cached openai-2.6.1-py3-none-any.whl.metadata (29 kB)
Collecting polygraphy (from tensorrt_llm)
  Using cached polygraphy-0.49.26-py2.py3-none-any.whl.metadata (5.8 kB)
Collecting psutil (from tensorrt_llm)
  Using cached psutil-7.1.2-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)
Collecting nvidia-ml-py<13,>=12 (from tensorrt_llm)
  Using cached nvidia_ml_py-12.575.51-py3-none-any.whl.metadata (9.3 kB)
Collecting pynvml==12.0.0 (from tensorrt_llm)
  Using cached pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)
Collecting pulp (from tensorrt_llm)
  Using cached pulp-3.3.0-py3-none-any.whl.metadata (8.4 kB)
Collecting pandas (from tensorrt_llm)
  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)
Collecting h5py==3.12.1 (from tensorrt_llm)
  Using cached h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)
Collecting StrEnum (from tensorrt_llm)
  Using cached StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)
Collecting sentencepiece>=0.1.99 (from tensorrt_llm)
  Using cached sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)
Collecting tensorrt~=10.11.0 (from tensorrt_llm)
  Using cached tensorrt-10.11.0.33.tar.gz (40 kB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Requirement already satisfied: torch<=2.8.0a0,>=2.7.1 in ./venv/lib/python3.12/site-packages (from tensorrt_llm) (2.7.1+cu128)
Requirement already satisfied: torchvision in ./venv/lib/python3.12/site-packages (from tensorrt_llm) (0.22.1+cu128)
Collecting nvidia-modelopt~=0.33.0 (from nvidia-modelopt[torch]~=0.33.0->tensorrt_llm)
  Using cached nvidia_modelopt-0.33.1-py3-none-manylinux_2_28_x86_64.whl.metadata (8.6 kB)
Requirement already satisfied: nvidia-nccl-cu12 in ./venv/lib/python3.12/site-packages (from tensorrt_llm) (2.26.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12 in ./venv/lib/python3.12/site-packages (from tensorrt_llm) (12.8.61)
Collecting transformers==4.53.1 (from tensorrt_llm)
  Using cached transformers-4.53.1-py3-none-any.whl.metadata (40 kB)
Collecting pydantic>=2.9.1 (from tensorrt_llm)
  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)
Collecting pydantic-settings[yaml] (from tensorrt_llm)
  Using cached pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)
Collecting omegaconf (from tensorrt_llm)
  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)
Collecting pillow==10.3.0 (from tensorrt_llm)
  Using cached pillow-10.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)
Collecting wheel<=0.45.1 (from tensorrt_llm)
  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)
Collecting optimum (from tensorrt_llm)
  Using cached optimum-2.0.0-py3-none-any.whl.metadata (14 kB)
Collecting datasets==3.1.0 (from tensorrt_llm)
  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)
Collecting evaluate (from tensorrt_llm)
  Using cached evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)
Requirement already satisfied: mpmath>=1.3.0 in ./venv/lib/python3.12/site-packages (from tensorrt_llm) (1.3.0)
Collecting click (from tensorrt_llm)
  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)
Collecting click_option_group (from tensorrt_llm)
  Using cached click_option_group-0.5.9-py3-none-any.whl.metadata (5.8 kB)
Collecting aenum (from tensorrt_llm)
  Using cached aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)
Collecting pyzmq (from tensorrt_llm)
  Using cached pyzmq-27.1.0-cp312-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (6.0 kB)
Collecting fastapi==0.115.4 (from tensorrt_llm)
  Using cached fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)
Collecting uvicorn (from tensorrt_llm)
  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)
Collecting setuptools<80 (from tensorrt_llm)
  Using cached setuptools-79.0.1-py3-none-any.whl.metadata (6.5 kB)
Collecting ordered-set (from tensorrt_llm)
  Using cached ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)
Collecting peft (from tensorrt_llm)
  Using cached peft-0.17.1-py3-none-any.whl.metadata (14 kB)
Collecting einops (from tensorrt_llm)
  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)
Collecting flashinfer-python==0.2.5 (from tensorrt_llm)
  Using cached flashinfer_python-0.2.5.tar.gz (2.5 MB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Collecting opencv-python-headless (from tensorrt_llm)
  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)
Collecting xgrammar==0.1.21 (from tensorrt_llm)
  Using cached xgrammar-0.1.21-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)
Collecting backoff (from tensorrt_llm)
  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)
Collecting nvtx (from tensorrt_llm)
  Using cached nvtx-0.2.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.6 kB)
Collecting matplotlib (from tensorrt_llm)
  Using cached matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
Collecting meson (from tensorrt_llm)
  Using cached meson-1.9.1-py3-none-any.whl.metadata (1.8 kB)
Collecting ninja (from tensorrt_llm)
  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)
Collecting etcd3 (from tensorrt_llm)
  Using cached etcd3-0.12.0.tar.gz (63 kB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Collecting blake3 (from tensorrt_llm)
  Using cached blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)
Collecting llguidance==0.7.29 (from tensorrt_llm)
  Using cached llguidance-0.7.29-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)
Collecting soundfile (from tensorrt_llm)
  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)
Requirement already satisfied: triton==3.3.1 in ./venv/lib/python3.12/site-packages (from tensorrt_llm) (3.3.1)
Collecting tiktoken (from tensorrt_llm)
  Using cached tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.7 kB)
Collecting blobfile (from tensorrt_llm)
  Using cached blobfile-3.1.0-py3-none-any.whl.metadata (15 kB)
Collecting protobuf>=4.25.8 (from tensorrt_llm)
  Using cached protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)
Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from datasets==3.1.0->tensorrt_llm) (3.19.1)
Collecting pyarrow>=15.0.0 (from datasets==3.1.0->tensorrt_llm)
  Using cached pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)
Collecting dill<0.3.9,>=0.3.0 (from datasets==3.1.0->tensorrt_llm)
  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)
Collecting requests>=2.32.2 (from datasets==3.1.0->tensorrt_llm)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting tqdm>=4.66.3 (from datasets==3.1.0->tensorrt_llm)
  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Collecting xxhash (from datasets==3.1.0->tensorrt_llm)
  Using cached xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
Collecting multiprocess<0.70.17 (from datasets==3.1.0->tensorrt_llm)
  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)
Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.1.0->tensorrt_llm)
  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)
Collecting aiohttp (from datasets==3.1.0->tensorrt_llm)
  Using cached aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)
Collecting huggingface-hub>=0.23.0 (from datasets==3.1.0->tensorrt_llm)
  Using cached huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)
Collecting packaging (from datasets==3.1.0->tensorrt_llm)
  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
Collecting pyyaml>=5.1 (from datasets==3.1.0->tensorrt_llm)
  Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
Collecting starlette<0.42.0,>=0.40.0 (from fastapi==0.115.4->tensorrt_llm)
  Using cached starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)
Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.12/site-packages (from fastapi==0.115.4->tensorrt_llm) (4.15.0)
Collecting huggingface-hub>=0.23.0 (from datasets==3.1.0->tensorrt_llm)
  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)
Collecting regex!=2019.12.17 (from transformers==4.53.1->tensorrt_llm)
  Using cached regex-2025.10.23-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)
Collecting tokenizers<0.22,>=0.21 (from transformers==4.53.1->tensorrt_llm)
  Using cached tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)
Collecting safetensors>=0.4.3 (from transformers==4.53.1->tensorrt_llm)
  Using cached safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
Collecting cuda-bindings~=12.9.4 (from cuda-python<13,>=12->tensorrt_llm)
  Using cached cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)
Collecting cuda-pathfinder~=1.1 (from cuda-bindings~=12.9.4->cuda-python<13,>=12->tensorrt_llm)
  Using cached cuda_pathfinder-1.3.2-py3-none-any.whl.metadata (1.9 kB)
Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.23.0->datasets==3.1.0->tensorrt_llm)
  Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)
Collecting nvidia-modelopt-core==0.33.1 (from nvidia-modelopt~=0.33.0->nvidia-modelopt[torch]~=0.33.0->tensorrt_llm)
  Using cached nvidia_modelopt_core-0.33.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (848 bytes)
Collecting rich (from nvidia-modelopt~=0.33.0->nvidia-modelopt[torch]~=0.33.0->tensorrt_llm)
  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)
Collecting scipy (from nvidia-modelopt~=0.33.0->nvidia-modelopt[torch]~=0.33.0->tensorrt_llm)
  Using cached scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)
Collecting torchprofile>=0.0.4 (from nvidia-modelopt~=0.33.0->nvidia-modelopt[torch]~=0.33.0->tensorrt_llm)
  Using cached torchprofile-0.0.4-py3-none-any.whl.metadata (303 bytes)
WARNING: nvidia-modelopt 0.33.1 does not provide the extra 'torch'
Collecting annotated-types>=0.6.0 (from pydantic>=2.9.1->tensorrt_llm)
  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)
Collecting pydantic-core==2.41.4 (from pydantic>=2.9.1->tensorrt_llm)
  Using cached pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)
Collecting typing-inspection>=0.4.2 (from pydantic>=2.9.1->tensorrt_llm)
  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)
Collecting anyio<5,>=3.4.0 (from starlette<0.42.0,>=0.40.0->fastapi==0.115.4->tensorrt_llm)
  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)
Collecting idna>=2.8 (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi==0.115.4->tensorrt_llm)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting sniffio>=1.1 (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi==0.115.4->tensorrt_llm)
  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)
Collecting tensorrt_cu12==10.11.0.33 (from tensorrt~=10.11.0->tensorrt_llm)
  Using cached tensorrt_cu12-10.11.0.33.tar.gz (18 kB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Installing backend dependencies ... done
  Preparing metadata (pyproject.toml) ... done
Collecting tensorrt_cu12_libs==10.11.0.33 (from tensorrt_cu12==10.11.0.33->tensorrt~=10.11.0->tensorrt_llm)
  Using cached tensorrt_cu12_libs-10.11.0.33.tar.gz (709 bytes)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Collecting tensorrt_cu12_bindings==10.11.0.33 (from tensorrt_cu12==10.11.0.33->tensorrt~=10.11.0->tensorrt_llm)
  Downloading tensorrt_cu12_bindings-10.11.0.33-cp312-none-manylinux_2_28_x86_64.whl.metadata (607 bytes)
Requirement already satisfied: nvidia-cuda-runtime-cu12 in ./venv/lib/python3.12/site-packages (from tensorrt_cu12_libs==10.11.0.33->tensorrt_cu12==10.11.0.33->tensorrt~=10.11.0->tensorrt_llm) (12.8.57)
Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (1.14.0)
Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (3.5)
Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (3.1.6)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (12.8.57)
Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (9.7.1.26)
Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (12.8.3.14)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (11.3.3.41)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (10.3.9.55)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (11.7.2.55)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (12.5.7.53)
Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (0.6.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (12.8.55)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (12.8.61)
Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in ./venv/lib/python3.12/site-packages (from torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (1.13.0.11)
Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->datasets==3.1.0->tensorrt_llm)
  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
Collecting aiosignal>=1.4.0 (from aiohttp->datasets==3.1.0->tensorrt_llm)
  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)
Collecting attrs>=17.3.0 (from aiohttp->datasets==3.1.0->tensorrt_llm)
  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)
Collecting frozenlist>=1.1.1 (from aiohttp->datasets==3.1.0->tensorrt_llm)
  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)
Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==3.1.0->tensorrt_llm)
  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)
Collecting propcache>=0.2.0 (from aiohttp->datasets==3.1.0->tensorrt_llm)
  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)
Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets==3.1.0->tensorrt_llm)
  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)
Collecting importlib_metadata (from diffusers>=0.27.0->tensorrt_llm)
  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)
Collecting ml_dtypes>=0.5.0 (from onnx>=1.18.0->tensorrt_llm)
  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)
Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets==3.1.0->tensorrt_llm)
  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets==3.1.0->tensorrt_llm)
  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets==3.1.0->tensorrt_llm)
  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)
Collecting pycryptodomex>=3.8 (from blobfile->tensorrt_llm)
  Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)
Collecting lxml>=4.9 (from blobfile->tensorrt_llm)
  Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)
Collecting pyproject_hooks (from build->tensorrt_llm)
  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)
Collecting grpcio>=1.27.1 (from etcd3->tensorrt_llm)
  Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)
Collecting six>=1.12.0 (from etcd3->tensorrt_llm)
  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting tenacity>=6.1.0 (from etcd3->tensorrt_llm)
  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)
Collecting zipp>=3.20 (from importlib_metadata->diffusers>=0.27.0->tensorrt_llm)
  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)
Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch<=2.8.0a0,>=2.7.1->tensorrt_llm) (2.1.5)
Collecting contourpy>=1.0.1 (from matplotlib->tensorrt_llm)
  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)
Collecting cycler>=0.10 (from matplotlib->tensorrt_llm)
  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting fonttools>=4.22.0 (from matplotlib->tensorrt_llm)
  Downloading fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (112 kB)
Collecting kiwisolver>=1.3.1 (from matplotlib->tensorrt_llm)
  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)
Collecting pyparsing>=3 (from matplotlib->tensorrt_llm)
  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)
Collecting python-dateutil>=2.7 (from matplotlib->tensorrt_llm)
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting antlr4-python3-runtime==4.9.* (from omegaconf->tensorrt_llm)
  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Preparing metadata (pyproject.toml) ... done
Collecting distro<2,>=1.7.0 (from openai->tensorrt_llm)
  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)
Collecting httpx<1,>=0.23.0 (from openai->tensorrt_llm)
  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
Collecting jiter<1,>=0.10.0 (from openai->tensorrt_llm)
  Downloading jiter-0.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)
Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->tensorrt_llm)
  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai->tensorrt_llm)
  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.
Collecting opencv-python-headless (from tensorrt_llm)
  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)
Collecting pytz>=2020.1 (from pandas->tensorrt_llm)
  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
Collecting tzdata>=2022.7 (from pandas->tensorrt_llm)
  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)
Collecting python-dotenv>=0.21.0 (from pydantic-settings[yaml]->tensorrt_llm)
  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)
Collecting markdown-it-py>=2.2.0 (from rich->nvidia-modelopt~=0.33.0->nvidia-modelopt[torch]~=0.33.0->tensorrt_llm)
  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)
Collecting pygments<3.0.0,>=2.13.0 (from rich->nvidia-modelopt~=0.33.0->nvidia-modelopt[torch]~=0.33.0->tensorrt_llm)
  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)
Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->nvidia-modelopt~=0.33.0->nvidia-modelopt[torch]~=0.33.0->tensorrt_llm)
  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)
Collecting cffi>=1.0 (from soundfile->tensorrt_llm)
  Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)
Collecting pycparser (from cffi>=1.0->soundfile->tensorrt_llm)
  Downloading pycparser-2.23-py3-none-any.whl.metadata (993 bytes)
Downloading datasets-3.1.0-py3-none-any.whl (480 kB)
Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)
Downloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 3.7 MB/s  0:00:01
Downloading llguidance-0.7.29-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.0/15.0 MB 3.6 MB/s  0:00:04
Downloading pillow-10.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 3.6 MB/s  0:00:01
Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)
Downloading transformers-4.53.1-py3-none-any.whl (10.8 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 3.5 MB/s  0:00:03
Downloading xgrammar-0.1.21-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 3.6 MB/s  0:00:03
Downloading cuda_python-12.9.4-py3-none-any.whl (7.6 kB)
Downloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 3.6 MB/s  0:00:03
Downloading cuda_pathfinder-1.3.2-py3-none-any.whl (27 kB)
Downloading dill-0.3.8-py3-none-any.whl (116 kB)
Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)
Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 566.1/566.1 kB 3.3 MB/s  0:00:00
Using cached hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)
Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)
Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.0/18.0 MB 3.6 MB/s  0:00:05
Downloading nvidia_ml_py-12.575.51-py3-none-any.whl (47 kB)
Downloading nvidia_modelopt-0.33.1-py3-none-manylinux_2_28_x86_64.whl (751 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 751.7/751.7 kB 3.3 MB/s  0:00:00
Downloading nvidia_modelopt_core-0.33.1-cp312-cp312-manylinux_2_28_x86_64.whl (1.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 3.5 MB/s  0:00:00
Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)
Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 3.5 MB/s  0:00:00
Downloading setuptools-79.0.1-py3-none-any.whl (1.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 3.5 MB/s  0:00:00
Downloading starlette-0.41.3-py3-none-any.whl (73 kB)
Using cached anyio-4.11.0-py3-none-any.whl (109 kB)
Downloading tensorrt_cu12_bindings-10.11.0.33-cp312-none-manylinux_2_28_x86_64.whl (1.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 3.5 MB/s  0:00:00
Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 3.6 MB/s  0:00:00
Using cached wheel-0.45.1-py3-none-any.whl (72 kB)
Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)
Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 3.5 MB/s  0:00:00
Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)
Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)
Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)
Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)
Downloading attrs-25.4.0-py3-none-any.whl (67 kB)
Downloading diffusers-0.35.2-py3-none-any.whl (4.1 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.1/4.1 MB 3.4 MB/s  0:00:01
Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 3.6 MB/s  0:00:05
Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 3.5 MB/s  0:00:01
Downloading onnx_graphsurgeon-0.5.8-py2.py3-none-any.whl (57 kB)
Using cached packaging-25.0-py3-none-any.whl (66 kB)
Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)
Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)
Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.7/47.7 MB 3.5 MB/s  0:00:13
Using cached pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)
Downloading regex-2025.10.23-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 803.4/803.4 kB 3.3 MB/s  0:00:00
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)
Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)
Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)
Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)
Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 3.4 MB/s  0:00:00
Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)
Downloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)
Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)
Downloading aenum-3.1.16-py3-none-any.whl (165 kB)
Downloading backoff-2.2.1-py3-none-any.whl (15 kB)
Downloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (388 kB)
Downloading blobfile-3.1.0-py3-none-any.whl (75 kB)
Downloading lxml-6.0.2-cp312-cp312-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 3.5 MB/s  0:00:01
Downloading pycryptodomex-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 3.5 MB/s  0:00:00
Downloading build-1.3.0-py3-none-any.whl (23 kB)
Downloading click-8.3.0-py3-none-any.whl (107 kB)
Downloading click_option_group-0.5.9-py3-none-any.whl (11 kB)
Downloading colored-2.3.1-py3-none-any.whl (19 kB)
Downloading einops-0.8.1-py3-none-any.whl (64 kB)
Downloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 3.6 MB/s  0:00:01
Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)
Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)
Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)
Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)
Downloading zipp-3.23.0-py3-none-any.whl (10 kB)
Downloading lark-1.3.1-py3-none-any.whl (113 kB)
Downloading matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.7/8.7 MB 3.5 MB/s  0:00:02
Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)
Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
Downloading fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 3.5 MB/s  0:00:01
Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 3.5 MB/s  0:00:00
Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)
Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Downloading meson-1.9.1-py3-none-any.whl (1.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 3.4 MB/s  0:00:00
Downloading mpi4py-4.1.1-cp312-cp312-manylinux1_x86_64.manylinux_2_5_x86_64.whl (1.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 3.5 MB/s  0:00:00
Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)
Downloading nvtx-0.2.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (545 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 545.6/545.6 kB 3.3 MB/s  0:00:00
Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)
Downloading openai-2.6.1-py3-none-any.whl (1.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 3.4 MB/s  0:00:00
Using cached distro-1.9.0-py3-none-any.whl (20 kB)
Using cached httpx-0.28.1-py3-none-any.whl (73 kB)
Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)
Downloading jiter-0.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)
Using cached h11-0.16.0-py3-none-any.whl (37 kB)
Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.0/50.0 MB 3.6 MB/s  0:00:14
Downloading optimum-2.0.0-py3-none-any.whl (162 kB)
Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)
Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 3.6 MB/s  0:00:03
Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)
Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)
Downloading peft-0.17.1-py3-none-any.whl (504 kB)
Downloading polygraphy-0.49.26-py2.py3-none-any.whl (372 kB)
Downloading psutil-7.1.2-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (258 kB)
Downloading pulp-3.3.0-py3-none-any.whl (16.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 3.5 MB/s  0:00:04
Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)
Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)
Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)
Downloading pyzmq-27.1.0-cp312-abi3-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (840 kB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 841.0/841.0 kB 3.4 MB/s  0:00:00
Using cached rich-14.2.0-py3-none-any.whl (243 kB)
Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)
Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)
Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)
Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 35.7/35.7 MB 3.5 MB/s  0:00:10
Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 3.5 MB/s  0:00:00
Downloading cffi-2.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (219 kB)
Downloading pycparser-2.23-py3-none-any.whl (118 kB)
Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)
Downloading tiktoken-0.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 3.1 MB/s  0:00:00
Downloading uvicorn-0.38.0-py3-none-any.whl (68 kB)
Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)
Building wheels for collected packages: tensorrt_llm, flashinfer-python, tensorrt, tensorrt_cu12, tensorrt_cu12_libs, etcd3, antlr4-python3-runtime
  Building wheel for tensorrt_llm (pyproject.toml) ... done
  Created wheel for tensorrt_llm: filename=tensorrt_llm-1.0.0-cp312-cp312-linux_x86_64.whl size=3559650032 sha256=60f20d80450bfc0676e4a19fe53bbf54bf29359d65b6515a3a0fa7c95d9fc52b
  Stored in directory: /home/m/.cache/pip/wheels/8c/4e/a0/338f0995ddba79677f1cc85cb22a20f4841167f86c7db6e59a
  Building wheel for flashinfer-python (pyproject.toml) ... done
  Created wheel for flashinfer-python: filename=flashinfer_python-0.2.5-py3-none-any.whl size=4124482 sha256=e7b4a799e056a24d0a3a315f7b963f3c396b34e0747eae0754098d625f899417
  Stored in directory: /home/m/.cache/pip/wheels/88/25/72/826d34ecab0d5e1a762f1762df1673f0cc029953de8744def3
  Building wheel for tensorrt (pyproject.toml) ... done
  Created wheel for tensorrt: filename=tensorrt-10.11.0.33-py2.py3-none-any.whl size=46729 sha256=b95737b88528c18479c95337eb86e86acd756e0a5528b07e0d5a680cad9d8b2d
  Stored in directory: /home/m/.cache/pip/wheels/e9/ef/67/9df1a5e26d847859dd55bf1b9cac93bf8ea711741423a379a2
  Building wheel for tensorrt_cu12 (pyproject.toml) ... done
  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.11.0.33-py2.py3-none-any.whl size=17580 sha256=6f889c3c7f49688b0d133a241072cb5097ddf21006fcb2e8b680c080ff723783
  Stored in directory: /home/m/.cache/pip/wheels/81/b2/2b/d6213221c3573bad34b02ba9c1431153063e38b95ca8fc3cba
  Building wheel for tensorrt_cu12_libs (pyproject.toml) ... done
  Created wheel for tensorrt_cu12_libs: filename=tensorrt_cu12_libs-10.11.0.33-py2.py3-none-manylinux_2_28_x86_64.whl size=3095447966 sha256=81ace8d3284fdbef0804c444a4d7555343ee079370e79c93cb328c7d9b08f968
  Stored in directory: /home/m/.cache/pip/wheels/4e/8d/1e/43cd645e7ece5c1135fb1dffcc29da7acaa4ee37aa39249ef8
  Building wheel for etcd3 (pyproject.toml) ... done
  Created wheel for etcd3: filename=etcd3-0.12.0-py2.py3-none-any.whl size=42975 sha256=dd1f78674ffa82b6bafc872463b4729623aff7ca79c210a354354859c342dff3
  Stored in directory: /home/m/.cache/pip/wheels/bb/ab/cb/8178a773ec0cee5434f923ad304941e794ed6a8392f0cd5f93
  Building wheel for antlr4-python3-runtime (pyproject.toml) ... done
  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=951e87a56a744a4552f338fddeebb88b5232cf10e5650a4a5809a2f35c105574
  Stored in directory: /home/m/.cache/pip/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd
Successfully built tensorrt_llm flashinfer-python tensorrt tensorrt_cu12 tensorrt_cu12_libs etcd3 antlr4-python3-runtime
Installing collected packages: tensorrt_cu12_bindings, StrEnum, pytz, nvtx, nvidia-ml-py, antlr4-python3-runtime, aenum, zipp, xxhash, wheel, urllib3, tzdata, typing-inspection, tqdm, tensorrt_cu12_libs, tenacity, sniffio, six, setuptools, sentencepiece, safetensors, regex, pyzmq, pyyaml, python-dotenv, pyproject_hooks, pyparsing, pynvml, pygments, pydantic-core, pycryptodomex, pycparser, pyarrow, pulp, psutil, protobuf, propcache, polygraphy, pillow, packaging, ordered-set, nvidia-modelopt-core, numpy, ninja, multidict, mpi4py, meson, mdurl, lxml, llguidance, lark, kiwisolver, jiter, idna, hf-xet, h11, grpcio, fsspec, frozenlist, fonttools, einops, distro, dill, cycler, cuda-pathfinder, colored, click, charset_normalizer, certifi, blake3, backoff, attrs, annotated-types, aiohappyeyeballs, yarl, uvicorn, tensorrt_cu12, scipy, requests, python-dateutil, pydantic, opencv-python-headless, omegaconf, multiprocess, ml_dtypes, markdown-it-py, importlib_metadata, httpcore, h5py, etcd3, cuda-bindings, contourpy, click_option_group, cffi, build, blobfile, anyio, aiosignal, tiktoken, tensorrt, starlette, soundfile, rich, pydantic-settings, pandas, onnx, matplotlib, huggingface-hub, httpx, cuda-python, aiohttp, tokenizers, openai, onnx_graphsurgeon, flashinfer-python, fastapi, diffusers, accelerate, transformers, torchprofile, datasets, xgrammar, peft, optimum, nvidia-modelopt, evaluate, tensorrt_llm
  Attempting uninstall: setuptools
    Found existing installation: setuptools 80.9.0
    Uninstalling setuptools-80.9.0:
      Successfully uninstalled setuptools-80.9.0
  Attempting uninstall: pillow
    Found existing installation: pillow 11.3.0
    Uninstalling pillow-11.3.0:
      Successfully uninstalled pillow-11.3.0
  Attempting uninstall: numpy
    Found existing installation: numpy 2.3.3
    Uninstalling numpy-2.3.3:
      Successfully uninstalled numpy-2.3.3
  Attempting uninstall: fsspec
    Found existing installation: fsspec 2025.9.0
    Uninstalling fsspec-2025.9.0:
      Successfully uninstalled fsspec-2025.9.0
Successfully installed StrEnum-0.4.15 accelerate-1.11.0 aenum-3.1.16 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 anyio-4.11.0 attrs-25.4.0 backoff-2.2.1 blake3-1.0.8 blobfile-3.1.0 build-1.3.0 certifi-2025.10.5 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.0 click_option_group-0.5.9 colored-2.3.1 contourpy-1.3.3 cuda-bindings-12.9.4 cuda-pathfinder-1.3.2 cuda-python-12.9.4 cycler-0.12.1 datasets-3.1.0 diffusers-0.35.2 dill-0.3.8 distro-1.9.0 einops-0.8.1 etcd3-0.12.0 evaluate-0.4.6 fastapi-0.115.4 flashinfer-python-0.2.5 fonttools-4.60.1 frozenlist-1.8.0 fsspec-2024.9.0 grpcio-1.76.0 h11-0.16.0 h5py-3.12.1 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 idna-3.11 importlib_metadata-8.7.0 jiter-0.11.1 kiwisolver-1.4.9 lark-1.3.1 llguidance-0.7.29 lxml-6.0.2 markdown-it-py-4.0.0 matplotlib-3.10.7 mdurl-0.1.2 meson-1.9.1 ml_dtypes-0.5.3 mpi4py-4.1.1 multidict-6.7.0 multiprocess-0.70.16 ninja-1.13.0 numpy-1.26.4 nvidia-ml-py-12.575.51 nvidia-modelopt-0.33.1 nvidia-modelopt-core-0.33.1 nvtx-0.2.13 omegaconf-2.3.0 onnx-1.19.1 onnx_graphsurgeon-0.5.8 openai-2.6.1 opencv-python-headless-4.11.0.86 optimum-2.0.0 ordered-set-4.1.0 packaging-25.0 pandas-2.3.3 peft-0.17.1 pillow-10.3.0 polygraphy-0.49.26 propcache-0.4.1 protobuf-6.33.0 psutil-7.1.2 pulp-3.3.0 pyarrow-22.0.0 pycparser-2.23 pycryptodomex-3.23.0 pydantic-2.12.3 pydantic-core-2.41.4 pydantic-settings-2.11.0 pygments-2.19.2 pynvml-12.0.0 pyparsing-3.2.5 pyproject_hooks-1.2.0 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pytz-2025.2 pyyaml-6.0.3 pyzmq-27.1.0 regex-2025.10.23 requests-2.32.5 rich-14.2.0 safetensors-0.6.2 scipy-1.16.3 sentencepiece-0.2.1 setuptools-79.0.1 six-1.17.0 sniffio-1.3.1 soundfile-0.13.1 starlette-0.41.3 tenacity-9.1.2 tensorrt-10.11.0.33 tensorrt_cu12-10.11.0.33 tensorrt_cu12_bindings-10.11.0.33 tensorrt_cu12_libs-10.11.0.33 tensorrt_llm-1.0.0 tiktoken-0.12.0 tokenizers-0.21.4 torchprofile-0.0.4 tqdm-4.67.1 transformers-4.53.1 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.38.0 wheel-0.45.1 xgrammar-0.1.21 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0
(venv) m@m-HP-Z440-Workstation:~/Desktop/1$ python 1.py
<frozen importlib._bootstrap_external>:1297: FutureWarning: The cuda.cuda module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.driver module instead.
<frozen importlib._bootstrap_external>:1297: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.
[2025-10-31 02:08:55] INFO config.py:54: PyTorch version 2.7.1+cu128 available.
2025-10-31 02:08:58,690 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
[TensorRT-LLM] TensorRT LLM version: 1.0.0
[10/31/2025-02:08:58] [TRT-LLM] [I] Using LLM with PyTorch backend
[10/31/2025-02:08:58] [TRT-LLM] [W] Using default gpus_per_node: 1
[10/31/2025-02:08:58] [TRT-LLM] [I] Set nccl_plugin to None.
[10/31/2025-02:08:58] [TRT-LLM] [I] neither checkpoint_format nor checkpoint_loader were provided, checkpoint_format will be set to HF.
eval_results.json: 100%|███████████████████████████████████████████████████████████████| 566/566 [00:00<00:00, 2.73MB/s]
.gitattributes: 1.52kB [00:00, 3.52MB/s]                                                      | 0.00/566 [00:00<?, ?B/s]
tokenizer_config.json: 1.29kB [00:00, 3.70MB/s]
special_tokens_map.json: 100%|█████████████████████████████████████████████████████████| 551/551 [00:00<00:00, 3.91MB/s]
tokenizer.json: 1.84MB [00:00, 13.4MB/s]s]
generation_config.json: 100%|███████████████████████████████████████████████████████████| 124/124 [00:00<00:00, 547kB/s]
config.json: 100%|█████████████████████████████████████████████████████████████████████| 608/608 [00:00<00:00, 2.93MB/s]
README.md: 3.20kB [00:00, 5.42MB/s]                                                           | 0.00/124 [00:00<?, ?B/s]
tokenizer.model: 100%|████████████████████████████████████████████████████████████████| 500k/500k [00:03<00:00, 130kB/s]
model.safetensors: 100%|███████████████████████████████████████████████████████████| 2.20G/2.20G [08:56<00:00, 4.10MB/s]
/home/m/Desktop/1/venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
rank 0 using MpiPoolSession to spawn MPI processes
<frozen importlib._bootstrap_external>:1297: FutureWarning: The cuda.cuda module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.driver module instead.
<frozen importlib._bootstrap_external>:1297: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.
[2025-10-31 02:18:05] INFO config.py:54: PyTorch version 2.7.1+cu128 available.
Multiple distributions found for package optimum. Picked distribution: optimum
2025-10-31 02:18:10,581 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
[TensorRT-LLM] TensorRT LLM version: 1.0.0
/home/m/Desktop/1/venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
[TensorRT-LLM][INFO] Refreshed the MPI local session
Loading safetensors weights in parallel: 100%|██████████| 1/1 [00:00<00:00, 69.98it/s]
Loading weights: 100%|██████████| 449/449 [00:00<00:00, 1039.64it/s]
Model init total -- 1.73s
[TensorRT-LLM][INFO] Number of tokens per block: 32.
[TensorRT-LLM][INFO] [MemUsageChange] Allocated 0.18 GiB for max tokens in paged KV cache (8352).
2025-10-31 02:18:15,168 - INFO - flashinfer.jit: Loading JIT ops: norm
/home/m/Desktop/1/venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
/home/m/Desktop/1/venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
2025-10-31 02:18:37,003 - INFO - flashinfer.jit: Finished loading JIT ops: norm
[TensorRT-LLM][INFO] Number of tokens per block: 32.
[TensorRT-LLM][INFO] [MemUsageChange] Allocated 10.89 GiB for max tokens in paged KV cache (518944).
Processed requests: 100%|█████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.90it/s]
Prompt: 'Hello, my name is', Generated text: '[Your Name] and I am a [Your Position] at [Your Company]. I am writing to express my interest in the [Job Title] position at'
Prompt: 'The capital of France is', Generated text: 'Paris.\n\n2. B. C. The capital of Canada is Ottawa.\n\n3. A. C. The capital of Australia is Can'
Prompt: 'The future of AI is', Generated text: "bright, and it's not just for big companies. Small businesses can also benefit from AI technology. Here are some ways:\n\n1."
(venv) m@m-HP-Z440-Workstation:~/Desktop/1$ 

